import os
import re
from typing import Dict, List, Optional

from .utils import (
    build_unified_results,
    compare_images,
    get_eval_directories,
    parse_vlm_score,
    save_json,
)

PROMPTS = {
    "00": "A crystal-clear ice cube resting on a sunlit wooden deck at midday, warm golden light reflecting off the wet surface, tiny droplets already forming around the cube.",
    "01": "A glittering ice cube embedded in a block of dry ice fog, surrounded by swirling cold vapor in a laboratory setting.",
    "02": "A pristine ice cube perched on a sizzling cast-iron skillet sitting over an open campfire, wisps of steam rising around it.",
    "03": "A single ice cube nestled on a snow-covered pine branch during a gray winter morning, frosty air surrounding the cube.",
    "04": "A solitary ice cube floating in a glass of iced tea on a café patio during a mild spring evening, condensation on the glass.",
    "05": "A thick ice cube positioned beneath a heat lamp in a photography studio, dramatic reflections highlighting the dripping water.",
    "06": "An ice cube placed on a marble countertop inside an air-conditioned kitchen, soft ambient lighting, room-temperature environment.",
    "07": "An ice cube resting on a beach towel near the shoreline, tropical sun overhead, waves gently lapping close by.",
    "08": "An ice cube sitting inside a stainless-steel freezer drawer, illuminated by cool blue LED lighting, frost crystals forming on nearby surfaces.",
    "09": "An ice cube suspended inside a cryogenic chamber filled with blue-tinted mist and frost-covered metal walls.",
}

def get_temperature_prompt(case_idx: str) -> str:
    """
    Generate VLM prompt for evaluating physical reasoning of ice cube melting.
    Uses the scenario description from PROMPTS to guide evaluation.
    """
    scenario = PROMPTS[case_idx]
    
    return f'''
You are evaluating a video generation model's ability to perform physical reasoning about temperature and phase transitions.

**Scenario Description:**
{scenario}

**Task:**
You are given two images:
1. The **first image** shows the initial state (an ice cube in the described environment).
2. The **second image** shows the final state (generated by a video model, representing what happened after some time).

**Your Goal:**
Evaluate whether the second image correctly demonstrates physical reasoning about how the ice cube would change in this specific environment. Consider:

**1. Melting Degree (Weight: 0.4)**
- Does the melting amount match the environment's temperature?
- Hot environments (sunlit deck, sizzling skillet, heat lamp, beach): Ice should be significantly or completely melted
- Cold environments (dry ice, freezer, cryogenic chamber, snowy branch): Ice should remain mostly intact or show minimal melting
- Moderate environments (room temperature, iced tea, air-conditioned kitchen): Ice should show partial melting
- Score: 0-100 (100 = perfect physical accuracy)

**2. Water/Liquid State (Weight: 0.3)**
- Is there appropriate water pooling or liquid formation?
- Hot environments: Should show visible water puddles, significant liquid formation
- Cold environments: Minimal to no liquid water
- Does the amount of liquid match the degree of melting?
- Score: 0-100

**3. Environmental Interaction (Weight: 0.2)**
- Does the ice cube's state match environmental cues (steam in hot places, frost in cold places)?
- Hot: Steam, vapor, rapid melting, wet surfaces
- Cold: Frost formation, ice preservation, minimal change
- Moderate: Gradual melting, condensation
- Score: 0-100

**4. Physical Realism (Weight: 0.1)**
- Does the overall scene look physically plausible?
- Are there any unrealistic artifacts (ice floating, wrong physics)?
- Is the ice cube's shape/structure consistent with its melting state?
- Score: 0-100

**Output Format:**
1. Present your detailed reasoning within <think> and </think> tags
2. For each aspect above, assign a score (0-100) and explain your reasoning
3. Calculate the final weighted score:
   Final Score = 0.4 × Melting_Degree + 0.3 × Water_State + 0.2 × Environmental_Interaction + 0.1 × Physical_Realism
4. Provide the final score within <answer> and </answer> tags as a single number

Be thorough and consider the physical laws of thermodynamics and phase transitions.
'''


def compute_temperature(
    name: str,
    local: bool = False,
    mode: str = "vreason_bench_standard",
) -> Dict:
    """
    Evaluate Temperature task by reading prediction frames from the `predictions`
    folder and comparing them against ground-truth images using a VLM.
    
    Expected layout:
      evaluations/Temperature/
        inputs/<idx>.png  (ground truth initial states)
        predictions/<model>_<idx>_seedK.png
        eval_results/temperature_eval.json
    """
    dirs = get_eval_directories("Temperature")
    gt_dir = dirs["input_dir"]
    predictions_dir = dirs["predictions_dir"]
    eval_results_dir = dirs["eval_results_dir"]
    
    os.makedirs(predictions_dir, exist_ok=True)
    os.makedirs(eval_results_dir, exist_ok=True)

    frame_files: List[str] = []
    for root, _, files in os.walk(predictions_dir):
        for fname in sorted(files):
            if fname.lower().endswith(".png"):
                frame_files.append(os.path.join(root, fname))

    results: Dict[str, Dict] = {}
    scores: List[float] = []

    for frame_path in frame_files:
        base_f = os.path.basename(frame_path)
        stem = os.path.splitext(base_f)[0]

        # Expect naming: <model>_<idx>_seedK
        m = re.match(
            r"^(?P<model>[^_]+)_(?P<idx>\d{2})_seed(?P<seed>[0-9A-Za-z]+)$",
            stem,
        )
        if not m:
            results[frame_path] = {
                "pred_frame": frame_path,
                "error": "invalid_filename",
            }
            continue

        model = m.group("model")
        idx_str = m.group("idx")

        gt_path = os.path.join(gt_dir, f"{idx_str}.png")
        if not os.path.exists(gt_path):
            results[frame_path] = {
                "pred_frame": frame_path,
                "error": "gt_not_found",
                "expected_gt": gt_path,
            }
            continue

        prompt = get_temperature_prompt(idx_str)
        cmp = compare_images(gt_path, frame_path, custom_prompt=prompt)
        vlm_text = cmp.get("comparison") or ""
        vlm_score = parse_vlm_score(vlm_text) or 0.0

        final_score = vlm_score
        scores.append(float(final_score))

        results[frame_path] = {
            "pred_frame": frame_path,
            "model": model,
            "ground_truth": gt_path,
            "vlm_text": vlm_text,
            "vlm_score": float(vlm_score),
            "score": float(final_score),
            "gt_index": idx_str,
        }

    unified = build_unified_results(
        results, 
        score_key="score", 
        threshold=60,
        predictions_dir=predictions_dir
    )
    
    unified["aggregate"]["task_metrics"] = {
        "average_vlm_score": float(sum(scores) / len(scores)) if scores else 0.0,
    }
    
    save_json(unified, os.path.join(eval_results_dir, "temperature_eval.json"))
    return unified
